AG/SA/preference page/User Roles page is taking much time to load
secure/SA/pdf format not working
secure/A/preference page is not loading

Unify - Release notes table is empty
Unify - In enroll page "you" text is not showing for logged in user



raviunifyso
Entreda@1110
otp


DOCKER HUB : UN : thallasaikiran7931
http://localhost:8081/

Docker is a popular platform for developing, shipping, and running applications in containers. Here's a list of fundamental Docker concepts to help you understand how Docker works:

Container:
A lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Containers are isolated from each other and share the host OS kernel.

Image:
A snapshot or template used to create a container. An image includes the application code, runtime, libraries, and other dependencies. Images are typically stored in a registry and can be versioned.

Dockerfile:
A text file that contains instructions for building a Docker image. It specifies the base image, any additional dependencies, and the steps to configure the container environment.

Registry:
A centralized repository for storing and sharing Docker images. Docker Hub is a popular public registry, and organizations often use private registries for their own images.

Containerization:
The process of encapsulating an application and its dependencies into a container, providing consistency across different environments and simplifying deployment.

Docker Engine:
The software responsible for building, running, and managing Docker containers. It includes the Docker daemon, REST API, and the CLI (Command Line Interface) for interacting with Docker.

Docker Compose:
A tool for defining and running multi-container Docker applications using a YAML file. Docker Compose allows you to specify services, networks, and volumes in a declarative manner.

Docker Hub:
A cloud-based registry service provided by Docker for sharing and distributing container images. It hosts both official and user-contributed Docker images.

Volume:
A mechanism for persisting data generated by a container. Volumes can be shared between containers and survive container restarts.

Network:
Docker provides networking capabilities to enable communication between containers. Docker networks can be user-defined or use the default bridge network.

Compose File:
A YAML file (usually named docker-compose.yml) that defines services, networks, and volumes for a Docker application. It is used with Docker Compose to deploy and manage multi-container applications.

Swarm Mode:
Docker Swarm is a native clustering and orchestration solution for Docker. Swarm Mode allows you to create and manage a cluster of Docker nodes, enabling high availability and scalability.

Service:
A definition for a set of containers running the same image, scaleable across multiple nodes in a Swarm. Services are the primary abstraction in Swarm Mode.

Node:
A physical or virtual machine that is part of a Docker Swarm cluster. Nodes can be either managers or workers, and they collaborate to run containers in the cluster.
These concepts form the foundation of Docker and are crucial for anyone working with containerized applications. Understanding how to build images, manage containers, and leverage Docker's features can greatly simplify the development and deployment process.

Docker:

A platform for building, running and shipping applicatios in a consistant manner
-own isolated environment
-packaged with all needed configuration
-one command to install the app
-run same app with 2 dif versions
Eg: if app is working in dev and not working in qa

Commands:
1.docker-compose up
2.docker-compose down --rmi all

Reasons:
1.One or more files missing
2.Software version mismatch
3.Different congig settings 

Container : It is an isolated environment for running an application
-containers are made of images(layers of images toped on each other), mostly linux base image (because small in size).With application image on top 

poatgres:10.10 -->layer-application image
second layer--
third layer --
alphine --> layer - linux base image

After containers application deployement:
-Developers and operations work together to package the application in a container
-No environmental configuration needed on server - except docker runtime

container                                 vs virtual machines
It is an isolated environment for   1.An abstract of a machine
running an application                 (physical hardware)
1.Allow running multiple apps in isolation
2.Are lightweight
3.Use OS of the host
4.Start quickly
5.Need less hardware resources

Docker Architecture:

           Rest API
CLient -------------------->server/Docker engine

Techinacally container is process, containers do not contain full blown operating system, instead all containers on the host share the os of the host.

***All containers share the kurnel of the host.

kernal is core of os, it manages applications and hardware resources(like memory &cpu)

 
image:
1.A cut down os 
2.A runtime environment (eg node)
3.Application
4.Third party libraries
5.Environment variables


Running linux
1.docker run ubuntu
2.docker ps
3.docker ps -a
4.docker run -it ubuntu
    1 echo hello
    2  whoami
    3  echo $0
    4  history

container & images
-Container is a runnning environment for image

Docker Basic commands:

-docker install redis
-docker run redis
-dokcer run -d redis (start new container with a command)
-docker stop 056397d950ef(id)
-docker start 056397d950ef
-docker ps -a (which will show all containers which are running/not running)
-docker run redis:4.0 (it is combination of pull & run)
-***docker run -p6000:6437 redis
    docker run -p6001:6437 redis:4.0
-***docker logs 056397d950ef(id/name)[for debugging the container]
-***docker run -d --name redis143 redis [for renaming the container]
-docker run -d --name redis143 redis
-****docker exec -it 9521af976c24 /bin/bash [for opening terminal of specific container for debugging purpose]-it interactive terminal
-docker network create mongo-network(name)


Commands:
  build       Build an image from a Dockerfile
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Display detailed information on one or more images
  load        Load an image from a tar archive or STDIN
  ls          List images
  prune       Remove unused images
  pull        Download an image from a registry
  push        Upload an image to a registry
  rm          Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE

workflow with docker

dev of app -->Git --->jenkins --->docker repo --->dev servers pulls both images
                         |
                     js    doc images (build js app & creates docker images)

-***docker run -p 27017:27017 -d -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=password --name mongodb --net mongo-network mongo

-***docker run -p 8081:8081 -d -e ME_CONFIG_MONGODB_ADMINUSERNAME=admin -e ME_CONFIG_MONGODB_ADMINPASSWORD=password --name mongo-express -e ME_CONFIG_MONGODB_SERVER=mongodb --net mongo-network mongo-express

-***docker-compose -f mongo.yaml up (for starting the container)
-***docker-compose -f mongo.yaml down (for starting the container)
----------------------------------------------------------
(***Dockerfile) Format:

FROM node:13-alpine

ENV MONGO_DB_USERNAME=admin \
    MONGO_DB_PWD=password

RUN mkdir -p /home/app

COPY . /home/app

CMD ["node", "server.js"]
-------------------------------------------------------------
in order to build an image by using docker file we need to specify 2 parameters
1.we want to give our image a name (docker build -t my-app:1.0) 
2.Allocation of a docker file (.)[current directory]

-docker ps -a | grep my-app (command used to filter required container from existing list of containers)
-docker remove Cid (command used to remove container)
-docker rmi imageId (command used to remove image)
-docker build -t my-app:1.0(for building a container)
-docker ps
-docker exec -it CName /bin/sh (to redirect to root directory of the container)
-ls
-env (should show env variables)
-ls /home/app
-----------------------------------------------------------
How to an image into private repository(AWS-ECR)
-open aws and create an ECR
-For each image we have its own repository, we cannot push multiple images into single repository(we push different images of same application with different versions)
-docker images
-docker login--$(aws ecr get-login --no-include-email --region eu-central-1)
-In aws ECR => docker pull registryDomain/imageName(link of ECR from AWS):10(tag/version)
-docker tag my-app:1.0 (address of aws ecr)/my-app:1.0 (docker tag = rename of image)
-docker push imageName(new image name/address of aws ecr)/
-docker build -t my-app:1.1 . (for rebuilding the docker image after updates)
-vim mongo-yaml
-docker-compose -f mongo.yaml up
--------------------------------------------------------------
Docker Volumes
-For data persistence
when you have databases and other stateful applications then we should use docker volumes
-Without docker volumes -container runs on a host- when we have data base container and that container has virtual file system where the data usually stored then data is gone restarting or removing the container(after restart container start from a fresh state)
-We connect host file system to virtual file system so during container restart data gets automatically replicated.

Volumes types;
docker run
1.Host volumes (u decide where on the host file system the reference is made)
-v /home/mount/data(host directory):/var/lib/mysql/data(container directory)
2.Anonymous volumes
-in this we just specify container directory & host directory will taken care by docker itself
-for each container a folder is generated thats get mounted automatically to the container
3.Named volumes***
-its an improvement of anonymous volumes, and it specifies the name of the folder of host systems
- -v name:/var/lib/mysql/data
-you can reference the volume by name
***volumes in docker compose
volumes:
- db-data:/var/lib/mysql/data 
--------------------------------------------- -------------
Docker volume locations

windows - C:\ProgramData\docker\volumes
linux   - /var/lib/docker/volumes
mac     - /var/lib/docker/volumes

-ls /var/lib/docker
-ls /var/lib/docker/volumes/


Kubernetes:

1.It is an open source container orchestration tool
2.Developed by google
3.Helps manage containerized applications in different deployment environments(physical & vistual machines and cloud environments)

Features of kubernetes
1.High availability or no downtime
2.Scalability or high performance (we increase or decrease as per load)
3.Disaster recovery - backup and restore

Kubernetes Architecture
1.master node connected with worker nodes(docker containers are present)

Master node actual runs several kub process which required to run and manage cluster properly
1.APi server (con) 7 UI
Entry point to the kub cluster
2.Controller Manager = keeps track of whats happening in the cluster
3.Scheduler = ensures pods placement
4.etcd = kubernetes backing store
5.Virtual network


Main Kubernetes Components
pod - abstracton of containers
Service - communication
Ingress - route traffic into cluster
configmap - external configuration
secret - external configuration
volume - data persistance
deployement - replication
StatefulSet - replication
 
Pod 
- smallest unit in kubernetes 
- abstract over container
- usually 1 app per pod 
- Each pod gets its own ip address
- pods communicate which each other internally using service 

Service
- permanet ip address 
- Lifecycle of pod and service are not connected
ingress

configmap
-Database URL usually in the built application
eg if endpoint service name is changed than we have to adjust the url in the applicatio
Re-build
push it to repo
pull new image in to your pod and restart

-config map helps in external configuration of your application
-configmap contains configuration data like urls & some other data
-config map connected to pod,so if you change the url, you just need to adjust the config file instead of repeating whole cycle

secret
-it is just like config map which is used to store secret data like creds,certificates(secret also connected to pod)

deployement
if app pod dies/downtime/stops
we are replicating app pod and DB pod which are conncected to main pods service
-service is also a load balancer

statefulset
- it is used for statefull applications and Data bases 
daemonset
-for creating replica we donot create new pod instead we define blueprint for app pods and specify how many replicas you 

volume - data storage
when pod get restarted the data would be gone 
By using volumes we attach physical storage to the pod that storage could be local storage(storage on local machine) or
remote storage(storage outside of the k8s cluster)

-pod is a layer of abstraction on top of containers.
-main/only entry point into kubernetes cluster is API service


minikube set up:
1.winget install minikube
2.


